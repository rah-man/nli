{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subtle-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = pd.read_json(path_or_buf='data.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convinced-cleanup",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pair</th>\n",
       "      <th>id_premis</th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>label</th>\n",
       "      <th>data_split</th>\n",
       "      <th>annotator_type</th>\n",
       "      <th>sentence_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101000</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Ia memiliki teman.</td>\n",
       "      <td>e</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101001</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Teman-temannya memiliki bagian juga.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101003</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Ia bermain di rumah sandiwara.</td>\n",
       "      <td>e</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101010</td>\n",
       "      <td>10101</td>\n",
       "      <td>Kualitas yang rendah ini dapat mengakibatkan k...</td>\n",
       "      <td>Komunikasi terganggu akibat kualitas tinggi.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101011</td>\n",
       "      <td>10101</td>\n",
       "      <td>Kualitas yang rendah ini dapat mengakibatkan k...</td>\n",
       "      <td>Komunikasi terganggu akibat kualitas rendah.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_pair  id_premis                                        premis_text  \\\n",
       "0   101000      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "1   101001      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "2   101003      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "3   101010      10101  Kualitas yang rendah ini dapat mengakibatkan k...   \n",
       "4   101011      10101  Kualitas yang rendah ini dapat mengakibatkan k...   \n",
       "\n",
       "                                hypothesis_text label data_split  \\\n",
       "0                            Ia memiliki teman.     e      train   \n",
       "1          Teman-temannya memiliki bagian juga.     n      train   \n",
       "2                Ia bermain di rumah sandiwara.     e      train   \n",
       "3  Komunikasi terganggu akibat kualitas tinggi.     n      train   \n",
       "4  Komunikasi terganggu akibat kualitas rendah.     n      train   \n",
       "\n",
       "  annotator_type sentence_size  \n",
       "0            lay        single  \n",
       "1            lay        single  \n",
       "2            lay        single  \n",
       "3            lay        single  \n",
       "4            lay        single  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTokenizer:\n",
    "  _whitespace_pattern = r\"\\s+\"\n",
    "  _tokenize_pattern = r'([0-9]+\\-an|[+-]?[0-9]*[,.]?[0-9]+|[A-Z][a-z]\\.|(?:[A-Z]+\\.)(?:[A-Za-z]+\\.){1,}|\\.\\.\\.|\\-\\-|\\w+(?=n\\'t)|n\\'t|\\w+(?=\\'[m|s]\\s)|\\'[m|s]\\s|[^\\w\\s+]|(?:[\\w-]{0,}))'\n",
    "\n",
    "  def __init__(self):\n",
    "    self.regex = re.compile(self._tokenize_pattern)\n",
    "    self.whitespace_regex = re.compile(self._whitespace_pattern)\n",
    "    \n",
    "  def tokenize(self, sent):\n",
    "    stripped_sent = self.whitespace_regex.sub(\" \", sent).strip()\n",
    "    tokens = self.regex.findall(stripped_sent)\n",
    "#     spaceafterflags = self.__getspaceafterflag(tokens)\n",
    "    tokens = [token for token in tokens if token != '']\n",
    "    return tokens\n",
    "  \n",
    "  def __getspaceafterflag(self, tokens):\n",
    "    flag = [False for token in tokens if token != '']\n",
    "\n",
    "    # Iterate over list\n",
    "    i = 0\n",
    "    is_whitespace = True\n",
    "    for token in tokens:\n",
    "      if token == '':\n",
    "        is_whitespace = True\n",
    "      else:\n",
    "        flag[i] = not is_whitespace\n",
    "        i += 1\n",
    "        is_whitespace = False\n",
    "\n",
    "    return flag[1:] + [False]\n",
    "  \n",
    "tokens = BaseTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_counter(*seq):\n",
    "  return [Counter(s) for s in seq]\n",
    "\n",
    "def intersect_counter(*seq):\n",
    "  intersection = seq[0].copy()\n",
    "  for s in seq[1:]:\n",
    "    intersection &= s\n",
    "  return intersection\n",
    "\n",
    "def union_counter(*seq):\n",
    "  union = seq[0].copy()\n",
    "  for s in seq[1:]:\n",
    "    union |= s\n",
    "  return union\n",
    "\n",
    "def count(counter):\n",
    "  return len(set(counter))\n",
    "\n",
    "def jaccard_sim(*seq, verb=False):\n",
    "  sequences = get_seq_counter(*seq)\n",
    "  intersection = count(intersect_counter(*sequences))\n",
    "  union = count(union_counter(*sequences))\n",
    "  \n",
    "  if verb:\n",
    "    print('intersect:', set(intersect_counter(*sequences)))\n",
    "    print('union:', set(union_counter(*sequences)))\n",
    "  \n",
    "  return intersection / union\n",
    "\n",
    "def intersection_len(*seq, premis=True, verb=False):\n",
    "  \"\"\"\n",
    "  seq[0] is the premis\n",
    "  seq[1] is the hypothesis\n",
    "  \"\"\"\n",
    "  sequences = get_seq_counter(*seq)\n",
    "  intersection = count(intersect_counter(*sequences))\n",
    "  denom = len(set(seq[0])) if premis else len(set(seq[1]))\n",
    "  \n",
    "  if verb:\n",
    "    print('intersect:', set(intersect_counter(*sequences)))\n",
    "    print('denom:', denom)\n",
    "    \n",
    "  return intersection / denom\n",
    "\n",
    "def cosine_ochiai(*seq):\n",
    "  sequences = get_seq_counter(*seq)\n",
    "  intersection = count(intersect_counter(*sequences))  \n",
    "  sequences = [count(s) for s in sequences]\n",
    "  prod = reduce(lambda x, y: x * y, sequences)    \n",
    "  return intersection / pow(prod, 1.0 / len(sequences))\n",
    "\n",
    "def show_matrix(m):\n",
    "  rows = len(m)\n",
    "  cols = len(m[0])\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      print(\"%4d\" % m[i][j], end=\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "def lcs(*seq, mode=0, punct=False, tokeniser='nltk'):\n",
    "  if tokeniser == 'nltk':\n",
    "    s1 = word_tokenize(re.sub(r'[\\.\\?\\'\"!,]','',seq[0]).lower()) if punct else word_tokenize(seq[0].lower())\n",
    "    s2 = word_tokenize(re.sub(r'[\\.\\?\\'\"!,]','',seq[1]).lower()) if punct else word_tokenize(seq[1].lower())\n",
    "  else:\n",
    "    s1 = tokens.tokenize(seq[0].lower())\n",
    "    s2 = tokens.tokenize(seq[1].lower())\n",
    "  n1 = len(s1); n2 = len(s2)\n",
    "  mat = np.zeros((n1+1,n2+1), dtype=np.int64)\n",
    "\n",
    "  for i in range(0, n1+1):\n",
    "    for j in range(0, n2+1):\n",
    "      if i == 0 or j == 0:\n",
    "        mat[i][j] = 0\n",
    "      elif s1[i-1] == s2[j-1]:\n",
    "        mat[i][j] = mat[i-1][j-1] + 1\n",
    "      else:\n",
    "        mat[i][j] = max( mat[i-1][j], mat[i][j-1] )\n",
    "\n",
    "#   show_matrix(mat)\n",
    "        \n",
    "  denom = len(s2) if mode else len(s1)\n",
    "  return mat[n1][n2] / denom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "maritime-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay['jaccard_sim'] = lay.apply(lambda x: jaccard_sim(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "# lay['intersection_premis'] = lay.apply(lambda x: intersection_len(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "lay['intersection_hypothesis'] = lay.apply(lambda x: intersection_len(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower()), premis=False), axis=1)\n",
    "lay['lcs_punct'] = lay.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1), axis=1)\n",
    "lay['lcs_nopunct'] = lay.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1, punct=True), axis=1)\n",
    "# lay['cosine_ochiai'] = lay.apply(lambda x: cosine_ochiai(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "lay['lcs_aksara'] = lay.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1, tokeniser='aksara'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coordinate-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pair</th>\n",
       "      <th>id_premis</th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>label</th>\n",
       "      <th>data_split</th>\n",
       "      <th>annotator_type</th>\n",
       "      <th>sentence_size</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101000</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Ia memiliki teman.</td>\n",
       "      <td>e</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101001</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Teman-temannya memiliki bagian juga.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101003</td>\n",
       "      <td>10100</td>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Ia bermain di rumah sandiwara.</td>\n",
       "      <td>e</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101010</td>\n",
       "      <td>10101</td>\n",
       "      <td>Kualitas yang rendah ini dapat mengakibatkan k...</td>\n",
       "      <td>Komunikasi terganggu akibat kualitas tinggi.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101011</td>\n",
       "      <td>10101</td>\n",
       "      <td>Kualitas yang rendah ini dapat mengakibatkan k...</td>\n",
       "      <td>Komunikasi terganggu akibat kualitas rendah.</td>\n",
       "      <td>n</td>\n",
       "      <td>train</td>\n",
       "      <td>lay</td>\n",
       "      <td>single</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_pair  id_premis                                        premis_text  \\\n",
       "0   101000      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "1   101001      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "2   101003      10100  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "3   101010      10101  Kualitas yang rendah ini dapat mengakibatkan k...   \n",
       "4   101011      10101  Kualitas yang rendah ini dapat mengakibatkan k...   \n",
       "\n",
       "                                hypothesis_text label data_split  \\\n",
       "0                            Ia memiliki teman.     e      train   \n",
       "1          Teman-temannya memiliki bagian juga.     n      train   \n",
       "2                Ia bermain di rumah sandiwara.     e      train   \n",
       "3  Komunikasi terganggu akibat kualitas tinggi.     n      train   \n",
       "4  Komunikasi terganggu akibat kualitas rendah.     n      train   \n",
       "\n",
       "  annotator_type sentence_size  jaccard_sim  intersection_hypothesis  \\\n",
       "0            lay        single     0.187500                 0.750000   \n",
       "1            lay        single     0.250000                 0.800000   \n",
       "2            lay        single     0.312500                 0.833333   \n",
       "3            lay        single     0.150000                 0.500000   \n",
       "4            lay        single     0.210526                 0.666667   \n",
       "\n",
       "   lcs_punct  lcs_nopunct  lcs_aksara  \n",
       "0   0.750000     0.666667    0.750000  \n",
       "1   0.400000     0.250000    0.400000  \n",
       "2   0.666667     0.600000    0.666667  \n",
       "3   0.333333     0.200000    0.333333  \n",
       "4   0.500000     0.400000    0.500000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "artificial-asthma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>nltk_prem</th>\n",
       "      <th>nltk_hyp</th>\n",
       "      <th>aksara_prem</th>\n",
       "      <th>aksara_hyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Kain mori pernah pula amat populer sebagai bah...</td>\n",
       "      <td>Kain mori tidak populer pada era 1970-an.</td>\n",
       "      <td>[kain, mori, pernah, pula, amat, populer, seba...</td>\n",
       "      <td>[kain, mori, tidak, populer, pada, era, 1970-a...</td>\n",
       "      <td>[kain, mori, pernah, pula, amat, populer, seba...</td>\n",
       "      <td>[kain, mori, tidak, populer, pada, era, 1970-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Dokter menyebut pemulihan Ada Zanusso yang ber...</td>\n",
       "      <td>Pemulihan Ada Zanusso adalah harapan baik.</td>\n",
       "      <td>[dokter, menyebut, pemulihan, ada, zanusso, ya...</td>\n",
       "      <td>[pemulihan, ada, zanusso, adalah, harapan, bai...</td>\n",
       "      <td>[dokter, menyebut, pemulihan, ada, zanusso, ya...</td>\n",
       "      <td>[pemulihan, ada, zanusso, adalah, harapan, bai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Dokter menyebut pemulihan Ada Zanusso yang ber...</td>\n",
       "      <td>Harapan baik seluruh dunia adalah Ada Zanusso.</td>\n",
       "      <td>[dokter, menyebut, pemulihan, ada, zanusso, ya...</td>\n",
       "      <td>[harapan, baik, seluruh, dunia, adalah, ada, z...</td>\n",
       "      <td>[dokter, menyebut, pemulihan, ada, zanusso, ya...</td>\n",
       "      <td>[harapan, baik, seluruh, dunia, adalah, ada, z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>Untuk pasar internasional, mesin untuk Auris h...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, internasional, ,, mesin, untuk,...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, internasional, ,, mesin, untuk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>Mesin untuk Auris di Jepang hanya 1.5 liter 1N...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[mesin, untuk, auris, di, jepang, hanya, 1.5, ...</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[mesin, untuk, auris, di, jepang, hanya, 1.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>1.5 liter 1NZ-FE dibutuhkan untuk Auris.</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[1.5, liter, 1nz-fe, dibutuhkan, untuk, auris, .]</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[1.5, liter, 1, nz-fe, dibutuhkan, untuk, auri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Untuk pasar domestik Jepang, mesin untuk Auris...</td>\n",
       "      <td>Auris butuh 2ZR-FE.</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[auris, butuh, 2zr-fe, .]</td>\n",
       "      <td>[untuk, pasar, domestik, jepang, ,, mesin, unt...</td>\n",
       "      <td>[auris, butuh, 2, zr-fe, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Jejaring Pendidikan Nasional (JARDIKNAS) merup...</td>\n",
       "      <td>Sekola bukan institusi pendidikan.</td>\n",
       "      <td>[jejaring, pendidikan, nasional, (, jardiknas,...</td>\n",
       "      <td>[sekola, bukan, institusi, pendidikan, .]</td>\n",
       "      <td>[jejaring, pendidikan, nasional, (, jardiknas,...</td>\n",
       "      <td>[sekola, bukan, institusi, pendidikan, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           premis_text  \\\n",
       "78   Kain mori pernah pula amat populer sebagai bah...   \n",
       "197  Dokter menyebut pemulihan Ada Zanusso yang ber...   \n",
       "199  Dokter menyebut pemulihan Ada Zanusso yang ber...   \n",
       "303  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "304  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "305  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "306  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "307  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "308  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "316  Jejaring Pendidikan Nasional (JARDIKNAS) merup...   \n",
       "\n",
       "                                       hypothesis_text  \\\n",
       "78           Kain mori tidak populer pada era 1970-an.   \n",
       "197         Pemulihan Ada Zanusso adalah harapan baik.   \n",
       "199     Harapan baik seluruh dunia adalah Ada Zanusso.   \n",
       "303  Untuk pasar internasional, mesin untuk Auris h...   \n",
       "304  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "305  Untuk pasar domestik Jepang, mesin untuk Auris...   \n",
       "306  Mesin untuk Auris di Jepang hanya 1.5 liter 1N...   \n",
       "307           1.5 liter 1NZ-FE dibutuhkan untuk Auris.   \n",
       "308                                Auris butuh 2ZR-FE.   \n",
       "316                 Sekola bukan institusi pendidikan.   \n",
       "\n",
       "                                             nltk_prem  \\\n",
       "78   [kain, mori, pernah, pula, amat, populer, seba...   \n",
       "197  [dokter, menyebut, pemulihan, ada, zanusso, ya...   \n",
       "199  [dokter, menyebut, pemulihan, ada, zanusso, ya...   \n",
       "303  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "304  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "305  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "306  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "307  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "308  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "316  [jejaring, pendidikan, nasional, (, jardiknas,...   \n",
       "\n",
       "                                              nltk_hyp  \\\n",
       "78   [kain, mori, tidak, populer, pada, era, 1970-a...   \n",
       "197  [pemulihan, ada, zanusso, adalah, harapan, bai...   \n",
       "199  [harapan, baik, seluruh, dunia, adalah, ada, z...   \n",
       "303  [untuk, pasar, internasional, ,, mesin, untuk,...   \n",
       "304  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "305  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "306  [mesin, untuk, auris, di, jepang, hanya, 1.5, ...   \n",
       "307  [1.5, liter, 1nz-fe, dibutuhkan, untuk, auris, .]   \n",
       "308                          [auris, butuh, 2zr-fe, .]   \n",
       "316          [sekola, bukan, institusi, pendidikan, .]   \n",
       "\n",
       "                                           aksara_prem  \\\n",
       "78   [kain, mori, pernah, pula, amat, populer, seba...   \n",
       "197  [dokter, menyebut, pemulihan, ada, zanusso, ya...   \n",
       "199  [dokter, menyebut, pemulihan, ada, zanusso, ya...   \n",
       "303  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "304  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "305  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "306  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "307  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "308  [untuk, pasar, domestik, jepang, ,, mesin, unt...   \n",
       "316  [jejaring, pendidikan, nasional, (, jardiknas,...   \n",
       "\n",
       "                                            aksara_hyp  \n",
       "78   [kain, mori, tidak, populer, pada, era, 1970-a...  \n",
       "197  [pemulihan, ada, zanusso, adalah, harapan, bai...  \n",
       "199  [harapan, baik, seluruh, dunia, adalah, ada, z...  \n",
       "303  [untuk, pasar, internasional, ,, mesin, untuk,...  \n",
       "304  [untuk, pasar, domestik, jepang, ,, mesin, unt...  \n",
       "305  [untuk, pasar, domestik, jepang, ,, mesin, unt...  \n",
       "306  [mesin, untuk, auris, di, jepang, hanya, 1.5, ...  \n",
       "307  [1.5, liter, 1, nz-fe, dibutuhkan, untuk, auri...  \n",
       "308                        [auris, butuh, 2, zr-fe, .]  \n",
       "316          [sekola, bukan, institusi, pendidikan, .]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = lay.loc[lay['lcs_punct'].ne(lay['lcs_aksara'])][['premis_text', 'hypothesis_text']]\n",
    "difference['nltk_prem'] = difference.apply(lambda x: word_tokenize(x.premis_text.lower()), axis=1) \n",
    "difference['nltk_hyp'] = difference.apply(lambda x: word_tokenize(x.hypothesis_text.lower()), axis=1)\n",
    "difference['aksara_prem'] = difference.apply(lambda x: tokens.tokenize(x.premis_text.lower()), axis=1) \n",
    "difference['aksara_hyp'] = difference.apply(lambda x: tokens.tokenize(x.hypothesis_text.lower()), axis=1)\n",
    "difference.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "employed-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference['nltk_p'] = difference.apply(lambda x: set(x.nltk_prem).difference(set(x.aksara_prem)), axis=1)\n",
    "difference['aksara_p'] = difference.apply(lambda x: set(x.aksara_prem).difference(set(x.nltk_prem)), axis=1)\n",
    "difference['nltk_h'] = difference.apply(lambda x: set(x.nltk_hyp).difference(set(x.aksara_hyp)), axis=1)\n",
    "difference['aksara_h'] = difference.apply(lambda x: set(x.aksara_hyp).difference(set(x.nltk_hyp)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "precious-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference[['premis_text', 'nltk_p', 'aksara_p']].to_csv('difference.csv', encoding='utf-16', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becoming-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "label                                                                 \n",
       "c         0.277778                 0.750000   0.666667     0.600000   \n",
       "e         0.320000                 0.833333   0.714286     0.666667   \n",
       "n         0.222222                 0.666667   0.555556     0.500000   \n",
       "\n",
       "       lcs_aksara  \n",
       "label              \n",
       "c        0.666667  \n",
       "e        0.727273  \n",
       "n        0.571429  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.groupby('label')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "manufactured-advisory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "sentence_size                                                                 \n",
       "double            0.238095                 0.750000   0.625000     0.571429   \n",
       "multiple          0.157895                 0.777778   0.666667     0.625000   \n",
       "single            0.285714                 0.750000   0.666667     0.600000   \n",
       "\n",
       "               lcs_aksara  \n",
       "sentence_size              \n",
       "double           0.625000  \n",
       "multiple         0.666667  \n",
       "single           0.666667  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.groupby('sentence_size')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "authentic-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "data_split                                                                 \n",
       "dev            0.277778                     0.75   0.647059          0.6   \n",
       "test           0.272727                     0.75   0.666667          0.6   \n",
       "train          0.269231                     0.75   0.666667          0.6   \n",
       "\n",
       "            lcs_aksara  \n",
       "data_split              \n",
       "dev           0.666667  \n",
       "test          0.666667  \n",
       "train         0.666667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.groupby('data_split')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-telephone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "heavy-bradford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pair</th>\n",
       "      <th>id_premis</th>\n",
       "      <th>author_label</th>\n",
       "      <th>annotation_round</th>\n",
       "      <th>label</th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>data_split</th>\n",
       "      <th>annotator_type</th>\n",
       "      <th>sentence_size</th>\n",
       "      <th>source</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31100</td>\n",
       "      <td>3110</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad bertani sejak sekitar 2000 tahun si...</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31101</td>\n",
       "      <td>3110</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Filipina mengekspor 2000 ton padi tahun lalu</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31102</td>\n",
       "      <td>3110</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad terkenal di Filipina.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31103</td>\n",
       "      <td>3110</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Sawah padi Batad berusia ribuan tahun.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31104</td>\n",
       "      <td>3110</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad tinggal di pantai.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_pair  id_premis author_label  annotation_round label  \\\n",
       "0    31100       3110            e                 1     e   \n",
       "1    31101       3110            n                 2     n   \n",
       "2    31102       3110            n                 1     n   \n",
       "3    31103       3110            e                 2     e   \n",
       "4    31104       3110            c                 2     c   \n",
       "\n",
       "                                         premis_text  \\\n",
       "0  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "1  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "2  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "3  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "4  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "\n",
       "                                     hypothesis_text data_split  \\\n",
       "0  Suku Batad bertani sejak sekitar 2000 tahun si...       test   \n",
       "1       Filipina mengekspor 2000 ton padi tahun lalu       test   \n",
       "2                   Suku Batad terkenal di Filipina.       test   \n",
       "3             Sawah padi Batad berusia ribuan tahun.       test   \n",
       "4                      Suku Batad tinggal di pantai.       test   \n",
       "\n",
       "  annotator_type sentence_size source    topics  \n",
       "0         expert        single   wiki  geografi  \n",
       "1         expert        single   wiki  geografi  \n",
       "2         expert        single   wiki  geografi  \n",
       "3         expert        single   wiki  geografi  \n",
       "4         expert        single   wiki  geografi  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert = pd.read_json(path_or_buf='expert.jsonl', lines=True)\n",
    "expert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "starting-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "olahraga               313\n",
       "film                   209\n",
       "margasatwa             203\n",
       "geografi               191\n",
       "person                 190\n",
       "bencana                188\n",
       "politik                179\n",
       "teknologi              164\n",
       "ekonomi                161\n",
       "budaya                 145\n",
       "entertainment          137\n",
       "soshum pendidikan      136\n",
       "saintek                131\n",
       "hukum/undang-undang    122\n",
       "kesehatan              118\n",
       "agama                  113\n",
       "profil perusahaan      111\n",
       "profil sekolah          89\n",
       "homepage pemerintah     84\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.topics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "liquid-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert['jaccard_sim'] = expert.apply(lambda x: jaccard_sim(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "# expert['intersection_premis'] = expert.apply(lambda x: intersection_len(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "expert['intersection_hypothesis'] = expert.apply(lambda x: intersection_len(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower()), premis=False), axis=1)\n",
    "expert['lcs_punct'] = expert.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1), axis=1)\n",
    "expert['lcs_nopunct'] = expert.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1, punct=True), axis=1)\n",
    "# expert['cosine_ochiai'] = expert.apply(lambda x: cosine_ochiai(word_tokenize(x.premis_text.lower()), word_tokenize(x.hypothesis_text.lower())), axis=1)\n",
    "expert['lcs_aksara'] = expert.apply(lambda x: lcs(x.premis_text, x.hypothesis_text, mode=1, tokeniser='aksara'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quick-journalism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pair</th>\n",
       "      <th>id_premis</th>\n",
       "      <th>author_label</th>\n",
       "      <th>annotation_round</th>\n",
       "      <th>label</th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>data_split</th>\n",
       "      <th>annotator_type</th>\n",
       "      <th>sentence_size</th>\n",
       "      <th>source</th>\n",
       "      <th>topics</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31100</td>\n",
       "      <td>3110</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad bertani sejak sekitar 2000 tahun si...</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31101</td>\n",
       "      <td>3110</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Filipina mengekspor 2000 ton padi tahun lalu</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31102</td>\n",
       "      <td>3110</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad terkenal di Filipina.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31103</td>\n",
       "      <td>3110</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Sawah padi Batad berusia ribuan tahun.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31104</td>\n",
       "      <td>3110</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>Filipina terkenal dengan pertanian padi bukitn...</td>\n",
       "      <td>Suku Batad tinggal di pantai.</td>\n",
       "      <td>test</td>\n",
       "      <td>expert</td>\n",
       "      <td>single</td>\n",
       "      <td>wiki</td>\n",
       "      <td>geografi</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_pair  id_premis author_label  annotation_round label  \\\n",
       "0    31100       3110            e                 1     e   \n",
       "1    31101       3110            n                 2     n   \n",
       "2    31102       3110            n                 1     n   \n",
       "3    31103       3110            e                 2     e   \n",
       "4    31104       3110            c                 2     c   \n",
       "\n",
       "                                         premis_text  \\\n",
       "0  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "1  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "2  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "3  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "4  Filipina terkenal dengan pertanian padi bukitn...   \n",
       "\n",
       "                                     hypothesis_text data_split  \\\n",
       "0  Suku Batad bertani sejak sekitar 2000 tahun si...       test   \n",
       "1       Filipina mengekspor 2000 ton padi tahun lalu       test   \n",
       "2                   Suku Batad terkenal di Filipina.       test   \n",
       "3             Sawah padi Batad berusia ribuan tahun.       test   \n",
       "4                      Suku Batad tinggal di pantai.       test   \n",
       "\n",
       "  annotator_type sentence_size source    topics  jaccard_sim  \\\n",
       "0         expert        single   wiki  geografi     0.238095   \n",
       "1         expert        single   wiki  geografi     0.263158   \n",
       "2         expert        single   wiki  geografi     0.277778   \n",
       "3         expert        single   wiki  geografi     0.200000   \n",
       "4         expert        single   wiki  geografi     0.150000   \n",
       "\n",
       "   intersection_hypothesis  lcs_punct  lcs_nopunct  lcs_aksara  \n",
       "0                 0.555556   0.333333     0.250000    0.333333  \n",
       "1                 0.714286   0.571429     0.571429    0.571429  \n",
       "2                 0.833333   0.500000     0.400000    0.500000  \n",
       "3                 0.571429   0.428571     0.333333    0.428571  \n",
       "4                 0.500000   0.500000     0.400000    0.500000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liable-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.150758</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "label                                                                 \n",
       "c         0.208333                 0.714286   0.625000     0.571429   \n",
       "e         0.210526                 0.700000   0.600000     0.533333   \n",
       "n         0.150758                 0.538462   0.444444     0.375000   \n",
       "\n",
       "       lcs_aksara  \n",
       "label              \n",
       "c        0.625000  \n",
       "e        0.600000  \n",
       "n        0.444444  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.groupby('label')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "massive-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    1041\n",
       "c     999\n",
       "n     944\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "formed-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "sentence_size                                                                 \n",
       "double            0.166667                 0.666667   0.571429          0.5   \n",
       "multiple          0.120000                 0.666667   0.555556          0.5   \n",
       "single            0.235294                 0.625000   0.545455          0.5   \n",
       "\n",
       "               lcs_aksara  \n",
       "sentence_size              \n",
       "double           0.571429  \n",
       "multiple         0.555556  \n",
       "single           0.545455  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.groupby('sentence_size')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "preliminary-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single      1534\n",
       "double      1043\n",
       "multiple     407\n",
       "Name: sentence_size, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.sentence_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "simplified-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.206623</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki/news</th>\n",
       "      <td>0.158947</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           jaccard_sim  intersection_hypothesis  lcs_punct  lcs_nopunct  \\\n",
       "source                                                                    \n",
       "news          0.206623                 0.666667   0.545455     0.500000   \n",
       "web           0.166667                 0.666667   0.583333     0.555556   \n",
       "wiki          0.185185                 0.666667   0.555556     0.500000   \n",
       "wiki/news     0.158947                 0.707143   0.571429     0.500000   \n",
       "\n",
       "           lcs_aksara  \n",
       "source                 \n",
       "news         0.545455  \n",
       "web          0.600000  \n",
       "wiki         0.555556  \n",
       "wiki/news    0.571429  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.groupby('source')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "effective-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news         1376\n",
       "wiki         1066\n",
       "web           284\n",
       "wiki/news     258\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "earned-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agama</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bencana</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.550505</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budaya</th>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ekonomi</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geografi</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homepage pemerintah</th>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hukum/undang-undang</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.440972</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kesehatan</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.639610</td>\n",
       "      <td>0.525575</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margasatwa</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olahraga</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.169048</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.449495</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politik</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profil perusahaan</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profil sekolah</th>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saintek</th>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soshum pendidikan</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teknologi</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jaccard_sim  intersection_hypothesis  lcs_punct  \\\n",
       "topics                                                                 \n",
       "agama                   0.150000                 0.714286   0.571429   \n",
       "bencana                 0.200000                 0.630682   0.550505   \n",
       "budaya                  0.163265                 0.666667   0.571429   \n",
       "ekonomi                 0.291667                 0.764706   0.666667   \n",
       "entertainment           0.225806                 0.666667   0.600000   \n",
       "film                    0.142857                 0.666667   0.583333   \n",
       "geografi                0.240000                 0.666667   0.555556   \n",
       "homepage pemerintah     0.205882                 0.700000   0.630682   \n",
       "hukum/undang-undang     0.156250                 0.600000   0.500000   \n",
       "kesehatan               0.200000                 0.639610   0.525575   \n",
       "margasatwa              0.185185                 0.642857   0.500000   \n",
       "olahraga                0.185185                 0.625000   0.500000   \n",
       "person                  0.169048                 0.625000   0.500000   \n",
       "politik                 0.238095                 0.700000   0.571429   \n",
       "profil perusahaan       0.150000                 0.666667   0.562500   \n",
       "profil sekolah          0.161765                 0.666667   0.625000   \n",
       "saintek                 0.241379                 0.666667   0.571429   \n",
       "soshum pendidikan       0.166667                 0.625000   0.538462   \n",
       "teknologi               0.214286                 0.630682   0.500000   \n",
       "\n",
       "                     lcs_nopunct  lcs_aksara  \n",
       "topics                                        \n",
       "agama                   0.500000    0.571429  \n",
       "bencana                 0.500000    0.550505  \n",
       "budaya                  0.500000    0.571429  \n",
       "ekonomi                 0.642857    0.666667  \n",
       "entertainment           0.555556    0.600000  \n",
       "film                    0.500000    0.600000  \n",
       "geografi                0.500000    0.555556  \n",
       "homepage pemerintah     0.585714    0.636364  \n",
       "hukum/undang-undang     0.440972    0.500000  \n",
       "kesehatan               0.483333    0.545455  \n",
       "margasatwa              0.454545    0.545455  \n",
       "olahraga                0.444444    0.500000  \n",
       "person                  0.449495    0.500000  \n",
       "politik                 0.545455    0.578947  \n",
       "profil perusahaan       0.500000    0.571429  \n",
       "profil sekolah          0.555556    0.625000  \n",
       "saintek                 0.500000    0.571429  \n",
       "soshum pendidikan       0.500000    0.538462  \n",
       "teknologi               0.444444    0.500000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.groupby('topics')[['jaccard_sim', 'intersection_hypothesis', 'lcs_punct', 'lcs_nopunct', 'lcs_aksara']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "female-federal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "olahraga               313\n",
       "film                   209\n",
       "margasatwa             203\n",
       "geografi               191\n",
       "person                 190\n",
       "bencana                188\n",
       "politik                179\n",
       "teknologi              164\n",
       "ekonomi                161\n",
       "budaya                 145\n",
       "entertainment          137\n",
       "soshum pendidikan      136\n",
       "saintek                131\n",
       "hukum/undang-undang    122\n",
       "kesehatan              118\n",
       "agama                  113\n",
       "profil perusahaan      111\n",
       "profil sekolah          89\n",
       "homepage pemerintah     84\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.topics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "advisory-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premis_text</th>\n",
       "      <th>hypothesis_text</th>\n",
       "      <th>nltk_prem</th>\n",
       "      <th>nltk_hyp</th>\n",
       "      <th>aksara_prem</th>\n",
       "      <th>aksara_hyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Lokasi kota Solok sangat strategis karena terl...</td>\n",
       "      <td>Jalan antar provinsi melewati kota Solok.</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, provinsi, melewati, kota, solok...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, provinsi, melewati, kota, solok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lokasi kota Solok sangat strategis karena terl...</td>\n",
       "      <td>Kota Solok ramai dilalui bus antar kota.</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[kota, solok, ramai, dilalui, bus, antar, kota...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[kota, solok, ramai, dilalui, bus, antar, kota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Lokasi kota Solok sangat strategis karena terl...</td>\n",
       "      <td>Jalan antar kabupaten/kota menghubungkan Solok...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, kabupaten/kota, menghubungkan, ...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, kabupaten, /, kota, menghubungk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Lokasi kota Solok sangat strategis karena terl...</td>\n",
       "      <td>Jalan antar provinsi sepanjang 90 kilometer me...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, provinsi, sepanjang, 90, kilome...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[jalan, antar, provinsi, sepanjang, 90, kilome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Lokasi kota Solok sangat strategis karena terl...</td>\n",
       "      <td>Lokasi kota Solok strategis sebagai kota pelab...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[lokasi, kota, solok, strategis, sebagai, kota...</td>\n",
       "      <td>[lokasi, kota, solok, sangat, strategis, karen...</td>\n",
       "      <td>[lokasi, kota, solok, strategis, sebagai, kota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Bupati Kotawaringin Timur saat ini adalah H. S...</td>\n",
       "      <td>H. Supian Hadi bukan bupati Kotawaringin Timur...</td>\n",
       "      <td>[bupati, kotawaringin, timur, saat, ini, adala...</td>\n",
       "      <td>[h., supian, hadi, bukan, bupati, kotawaringin...</td>\n",
       "      <td>[bupati, kotawaringin, timur, saat, ini, adala...</td>\n",
       "      <td>[h, ., supian, hadi, bukan, bupati, kotawaring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Harry Potter adalah seri tujuh novel fantasi y...</td>\n",
       "      <td>Novel Harry Potter ditulis oleh J.K. Rowling.</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[novel, harry, potter, ditulis, oleh, j.k., ro...</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[novel, harry, potter, ditulis, oleh, j, ., k,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Harry Potter adalah seri tujuh novel fantasi y...</td>\n",
       "      <td>Ronald Weasley bersahabat dengan J.K. Rowling</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[ronald, weasley, bersahabat, dengan, j.k., ro...</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[ronald, weasley, bersahabat, dengan, j, ., k,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Harry Potter adalah seri tujuh novel fantasi y...</td>\n",
       "      <td>J.K. Rowling suka bertualang.</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[j.k., rowling, suka, bertualang, .]</td>\n",
       "      <td>[harry, potter, adalah, seri, tujuh, novel, fa...</td>\n",
       "      <td>[j, ., k, ., rowling, suka, bertualang, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Setiap novel mengisahkan tentang satu tahun ke...</td>\n",
       "      <td>Setiap novel mengisahkan kehidupan Harry antar...</td>\n",
       "      <td>[setiap, novel, mengisahkan, tentang, satu, ta...</td>\n",
       "      <td>[setiap, novel, mengisahkan, kehidupan, harry,...</td>\n",
       "      <td>[setiap, novel, mengisahkan, tentang, satu, ta...</td>\n",
       "      <td>[setiap, novel, mengisahkan, kehidupan, harry,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           premis_text  \\\n",
       "54   Lokasi kota Solok sangat strategis karena terl...   \n",
       "55   Lokasi kota Solok sangat strategis karena terl...   \n",
       "56   Lokasi kota Solok sangat strategis karena terl...   \n",
       "57   Lokasi kota Solok sangat strategis karena terl...   \n",
       "58   Lokasi kota Solok sangat strategis karena terl...   \n",
       "90   Bupati Kotawaringin Timur saat ini adalah H. S...   \n",
       "501  Harry Potter adalah seri tujuh novel fantasi y...   \n",
       "503  Harry Potter adalah seri tujuh novel fantasi y...   \n",
       "505  Harry Potter adalah seri tujuh novel fantasi y...   \n",
       "519  Setiap novel mengisahkan tentang satu tahun ke...   \n",
       "\n",
       "                                       hypothesis_text  \\\n",
       "54           Jalan antar provinsi melewati kota Solok.   \n",
       "55            Kota Solok ramai dilalui bus antar kota.   \n",
       "56   Jalan antar kabupaten/kota menghubungkan Solok...   \n",
       "57   Jalan antar provinsi sepanjang 90 kilometer me...   \n",
       "58   Lokasi kota Solok strategis sebagai kota pelab...   \n",
       "90   H. Supian Hadi bukan bupati Kotawaringin Timur...   \n",
       "501      Novel Harry Potter ditulis oleh J.K. Rowling.   \n",
       "503      Ronald Weasley bersahabat dengan J.K. Rowling   \n",
       "505                      J.K. Rowling suka bertualang.   \n",
       "519  Setiap novel mengisahkan kehidupan Harry antar...   \n",
       "\n",
       "                                             nltk_prem  \\\n",
       "54   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "55   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "56   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "57   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "58   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "90   [bupati, kotawaringin, timur, saat, ini, adala...   \n",
       "501  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "503  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "505  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "519  [setiap, novel, mengisahkan, tentang, satu, ta...   \n",
       "\n",
       "                                              nltk_hyp  \\\n",
       "54   [jalan, antar, provinsi, melewati, kota, solok...   \n",
       "55   [kota, solok, ramai, dilalui, bus, antar, kota...   \n",
       "56   [jalan, antar, kabupaten/kota, menghubungkan, ...   \n",
       "57   [jalan, antar, provinsi, sepanjang, 90, kilome...   \n",
       "58   [lokasi, kota, solok, strategis, sebagai, kota...   \n",
       "90   [h., supian, hadi, bukan, bupati, kotawaringin...   \n",
       "501  [novel, harry, potter, ditulis, oleh, j.k., ro...   \n",
       "503  [ronald, weasley, bersahabat, dengan, j.k., ro...   \n",
       "505               [j.k., rowling, suka, bertualang, .]   \n",
       "519  [setiap, novel, mengisahkan, kehidupan, harry,...   \n",
       "\n",
       "                                           aksara_prem  \\\n",
       "54   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "55   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "56   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "57   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "58   [lokasi, kota, solok, sangat, strategis, karen...   \n",
       "90   [bupati, kotawaringin, timur, saat, ini, adala...   \n",
       "501  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "503  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "505  [harry, potter, adalah, seri, tujuh, novel, fa...   \n",
       "519  [setiap, novel, mengisahkan, tentang, satu, ta...   \n",
       "\n",
       "                                            aksara_hyp  \n",
       "54   [jalan, antar, provinsi, melewati, kota, solok...  \n",
       "55   [kota, solok, ramai, dilalui, bus, antar, kota...  \n",
       "56   [jalan, antar, kabupaten, /, kota, menghubungk...  \n",
       "57   [jalan, antar, provinsi, sepanjang, 90, kilome...  \n",
       "58   [lokasi, kota, solok, strategis, sebagai, kota...  \n",
       "90   [h, ., supian, hadi, bukan, bupati, kotawaring...  \n",
       "501  [novel, harry, potter, ditulis, oleh, j, ., k,...  \n",
       "503  [ronald, weasley, bersahabat, dengan, j, ., k,...  \n",
       "505         [j, ., k, ., rowling, suka, bertualang, .]  \n",
       "519  [setiap, novel, mengisahkan, kehidupan, harry,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_diff = expert.loc[expert['lcs_punct'].ne(expert['lcs_aksara'])][['premis_text', 'hypothesis_text']]\n",
    "expert_diff['nltk_prem'] = expert_diff.apply(lambda x: word_tokenize(x.premis_text.lower()), axis=1) \n",
    "expert_diff['nltk_hyp'] = expert_diff.apply(lambda x: word_tokenize(x.hypothesis_text.lower()), axis=1)\n",
    "expert_diff['aksara_prem'] = expert_diff.apply(lambda x: tokens.tokenize(x.premis_text.lower()), axis=1) \n",
    "expert_diff['aksara_hyp'] = expert_diff.apply(lambda x: tokens.tokenize(x.hypothesis_text.lower()), axis=1)\n",
    "expert_diff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "consistent-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_diff['nltk_p'] = expert_diff.apply(lambda x: set(x.nltk_prem).difference(set(x.aksara_prem)), axis=1)\n",
    "expert_diff['aksara_p'] = expert_diff.apply(lambda x: set(x.aksara_prem).difference(set(x.nltk_prem)), axis=1)\n",
    "expert_diff['nltk_h'] = expert_diff.apply(lambda x: set(x.nltk_hyp).difference(set(x.aksara_hyp)), axis=1)\n",
    "expert_diff['aksara_h'] = expert_diff.apply(lambda x: set(x.aksara_hyp).difference(set(x.nltk_hyp)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "joined-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_diff[['premis_text', 'nltk_p', 'aksara_p']].to_csv('expert_difference.csv', encoding='utf-16', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "difficult-refund",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2984"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "useful-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pair</th>\n",
       "      <th>id_premis</th>\n",
       "      <th>annotation_round</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>lcs_punct</th>\n",
       "      <th>lcs_nopunct</th>\n",
       "      <th>lcs_aksara</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39714.800268</td>\n",
       "      <td>3971.231568</td>\n",
       "      <td>1.248660</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>0.647621</td>\n",
       "      <td>0.571489</td>\n",
       "      <td>0.518496</td>\n",
       "      <td>0.573621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5737.780456</td>\n",
       "      <td>573.779051</td>\n",
       "      <td>0.544837</td>\n",
       "      <td>0.180223</td>\n",
       "      <td>0.201935</td>\n",
       "      <td>0.207796</td>\n",
       "      <td>0.232306</td>\n",
       "      <td>0.207696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31100.000000</td>\n",
       "      <td>3110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34400.750000</td>\n",
       "      <td>3440.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39210.500000</td>\n",
       "      <td>3921.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44283.250000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.723485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50475.000000</td>\n",
       "      <td>5047.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_pair    id_premis  annotation_round  jaccard_sim  \\\n",
       "count   2984.000000  2984.000000       2984.000000  2984.000000   \n",
       "mean   39714.800268  3971.231568          1.248660     0.242849   \n",
       "std     5737.780456   573.779051          0.544837     0.180223   \n",
       "min    31100.000000  3110.000000          1.000000     0.019608   \n",
       "25%    34400.750000  3440.000000          1.000000     0.125000   \n",
       "50%    39210.500000  3921.000000          1.000000     0.187500   \n",
       "75%    44283.250000  4428.000000          1.000000     0.290323   \n",
       "max    50475.000000  5047.000000          3.000000     1.000000   \n",
       "\n",
       "       intersection_hypothesis    lcs_punct  lcs_nopunct   lcs_aksara  \n",
       "count              2984.000000  2984.000000  2984.000000  2984.000000  \n",
       "mean                  0.647621     0.571489     0.518496     0.573621  \n",
       "std                   0.201935     0.207796     0.232306     0.207696  \n",
       "min                   0.083333     0.076923     0.000000     0.076923  \n",
       "25%                   0.500000     0.416667     0.333333     0.416667  \n",
       "50%                   0.666667     0.555556     0.500000     0.555556  \n",
       "75%                   0.812500     0.714286     0.666667     0.723485  \n",
       "max                   1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-brighton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "charged-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuk pasar domestik Jepang, mesin untuk Auris hanya 1.5 liter 1NZ-FE dan 1.8 liter 2ZR-FE.\n",
      "['Untuk', 'pasar', 'domestik', 'Jepang', ',', 'mesin', 'untuk', 'Auris', 'hanya', '1.5', 'liter', '1', 'NZ-FE', 'dan', '1.8', 'liter', '2', 'ZR-FE', '.']\n",
      "['Untuk', 'pasar', 'domestik', 'Jepang', ',', 'mesin', 'untuk', 'Auris', 'hanya', '1.5', 'liter', '1NZ-FE', 'dan', '1.8', 'liter', '2ZR-FE', '.']\n",
      "Untuk pasar internasional, mesin untuk Auris hanya 1.5 liter 1NZ-FE dan 1.8 liter 2ZR-FE.\n",
      "['Untuk', 'pasar', 'internasional', ',', 'mesin', 'untuk', 'Auris', 'hanya', '1.5', 'liter', '1', 'NZ-FE', 'dan', '1.8', 'liter', '2', 'ZR-FE', '.']\n",
      "['Untuk', 'pasar', 'internasional', ',', 'mesin', 'untuk', 'Auris', 'hanya', '1.5', 'liter', '1NZ-FE', 'dan', '1.8', 'liter', '2ZR-FE', '.']\n"
     ]
    }
   ],
   "source": [
    "a, b = data.iloc[303].premis_text, data.iloc[303].hypothesis_text \n",
    "tokens = BaseTokenizer()\n",
    "print(a)\n",
    "print(tokens.tokenize(a))\n",
    "print(word_tokenize(a))\n",
    "print(b)\n",
    "print(tokens.tokenize(b))\n",
    "print(word_tokenize(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addressed-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3872983346207417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = data.iloc[0].premis_text, data.iloc[0].hypothesis_text \n",
    "cosine_ochiai(word_tokenize(a.lower()), word_tokenize(b.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "grateful-choir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premis: Selain itu, ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain.\n",
      "Hypothesis: Ia memiliki teman. \n",
      "\n",
      "intersect: {'memiliki', '.', 'ia'}\n",
      "union: {'memiliki', ',', 'dari', 'sandiwara', 'dan', '.', 'juga', 'selain', 'teman-temannya', 'tempat', 'teman', 'andil', 'bermain', 'ia', 'rumah', 'itu'}\n",
      "Jaccard: 0.1875 \n",
      "\n",
      "intersect: {'memiliki', '.', 'ia'}\n",
      "denom: 15\n",
      "Intersection premis: 0.2 \n",
      "\n",
      "intersect: {'memiliki', '.', 'ia'}\n",
      "denom: 4\n",
      "Intersection hypothesis: 0.75 \n",
      "\n",
      "Cosine ochiai: 0.3872983346207417\n",
      "\n",
      "============================================\n",
      "\n",
      "Premis: Selain itu, ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain.\n",
      "Hypothesis: Teman-temannya memiliki bagian juga. \n",
      "\n",
      "intersect: {'memiliki', 'teman-temannya', '.', 'juga'}\n",
      "union: {'memiliki', ',', 'dari', 'sandiwara', 'dan', '.', 'bagian', 'juga', 'selain', 'teman-temannya', 'tempat', 'andil', 'bermain', 'ia', 'rumah', 'itu'}\n",
      "Jaccard: 0.25 \n",
      "\n",
      "intersect: {'memiliki', 'teman-temannya', '.', 'juga'}\n",
      "denom: 15\n",
      "Intersection premis: 0.26666666666666666 \n",
      "\n",
      "intersect: {'memiliki', 'teman-temannya', '.', 'juga'}\n",
      "denom: 5\n",
      "Intersection hypothesis: 0.8 \n",
      "\n",
      "Cosine ochiai: 0.46188021535170054\n",
      "\n",
      "============================================\n",
      "\n",
      "Premis: Selain itu, ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain.\n",
      "Hypothesis: Ia bermain di rumah sandiwara. \n",
      "\n",
      "intersect: {'sandiwara', '.', 'bermain', 'ia', 'rumah'}\n",
      "union: {'memiliki', ',', 'dari', 'sandiwara', 'dan', '.', 'juga', 'selain', 'teman-temannya', 'tempat', 'andil', 'bermain', 'ia', 'rumah', 'itu', 'di'}\n",
      "Jaccard: 0.3125 \n",
      "\n",
      "intersect: {'sandiwara', '.', 'bermain', 'ia', 'rumah'}\n",
      "denom: 15\n",
      "Intersection premis: 0.3333333333333333 \n",
      "\n",
      "intersect: {'sandiwara', '.', 'bermain', 'ia', 'rumah'}\n",
      "denom: 6\n",
      "Intersection hypothesis: 0.8333333333333334 \n",
      "\n",
      "Cosine ochiai: 0.5270462766947299\n",
      "\n",
      "============================================\n",
      "\n",
      "Premis: Kualitas yang rendah ini dapat mengakibatkan komunikasi menjadi tergganggu, mulai dari putus-putus sampai drop call.\n",
      "Hypothesis: Komunikasi terganggu akibat kualitas tinggi. \n",
      "\n",
      "intersect: {'.', 'kualitas', 'komunikasi'}\n",
      "union: {'terganggu', 'call', 'ini', 'tergganggu', ',', 'dapat', 'komunikasi', 'sampai', 'drop', 'kualitas', 'menjadi', 'mengakibatkan', 'rendah', 'akibat', 'mulai', 'tinggi', 'dari', 'yang', 'putus-putus', '.'}\n",
      "Jaccard: 0.15 \n",
      "\n",
      "intersect: {'.', 'kualitas', 'komunikasi'}\n",
      "denom: 17\n",
      "Intersection premis: 0.17647058823529413 \n",
      "\n",
      "intersect: {'.', 'kualitas', 'komunikasi'}\n",
      "denom: 6\n",
      "Intersection hypothesis: 0.5 \n",
      "\n",
      "Cosine ochiai: 0.2970442628930023\n",
      "\n",
      "============================================\n",
      "\n",
      "Premis: Kualitas yang rendah ini dapat mengakibatkan komunikasi menjadi tergganggu, mulai dari putus-putus sampai drop call.\n",
      "Hypothesis: Komunikasi terganggu akibat kualitas rendah. \n",
      "\n",
      "intersect: {'rendah', '.', 'kualitas', 'komunikasi'}\n",
      "union: {'terganggu', 'call', 'ini', 'tergganggu', ',', 'dapat', 'komunikasi', 'sampai', 'drop', 'kualitas', 'menjadi', 'mengakibatkan', 'rendah', 'akibat', 'mulai', 'dari', 'yang', 'putus-putus', '.'}\n",
      "Jaccard: 0.21052631578947367 \n",
      "\n",
      "intersect: {'rendah', '.', 'kualitas', 'komunikasi'}\n",
      "denom: 17\n",
      "Intersection premis: 0.23529411764705882 \n",
      "\n",
      "intersect: {'rendah', '.', 'kualitas', 'komunikasi'}\n",
      "denom: 6\n",
      "Intersection hypothesis: 0.6666666666666666 \n",
      "\n",
      "Cosine ochiai: 0.39605901719066977\n",
      "\n",
      "============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  p, h = data.iloc[i].premis_text, data.iloc[i].hypothesis_text  \n",
    "  print('Premis:', p)\n",
    "  print('Hypothesis:', h, '\\n')\n",
    "  print('Jaccard:', jaccard_sim(word_tokenize(p.lower()), word_tokenize(h.lower()), verb=True), '\\n')\n",
    "  print('Intersection premis:', intersection_len(word_tokenize(p.lower()), word_tokenize(h.lower()), verb=True), '\\n')\n",
    "  print('Intersection hypothesis:', intersection_len(word_tokenize(p.lower()), word_tokenize(h.lower()), premis=False, verb=True), '\\n')\n",
    "  print('Cosine ochiai:', cosine_ochiai(word_tokenize(p.lower()), word_tokenize(h.lower())))\n",
    "  print('\\n============================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "crude-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['selain', 'itu', 'ia', 'juga', 'memiliki', 'andil', 'dari', 'rumah', 'sandiwara', 'tempat', 'ia', 'dan', 'temantemannya', 'bermain']\n",
      "['ia', 'memiliki', 'teman']\n",
      "Selain itu, ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain.\n",
      "Selain itu ia juga memiliki andil dari rumah sandiwara tempat ia dan temantemannya bermain\n",
      "Selain itu ia juga memiliki andil dari rumah sandiwara tempat ia dan temantemannya bermain\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(re.sub(r'[^\\w\\s]','',a).lower()))\n",
    "print(word_tokenize(re.sub(r'[^\\w\\s]','',b).lower()))\n",
    "print(a)\n",
    "print(a.translate(str.maketrans('', '', string.punctuation)))\n",
    "print(re.sub(r'[^\\w\\s]','',a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "effective-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 = Selain itu, ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain.\n",
      "s2 = Teman-temannya memiliki bagian juga.\n",
      "Selain itu ia juga memiliki andil dari rumah sandiwara tempat ia dan teman-temannya bermain\n",
      "Teman-temannya memiliki bagian juga\n",
      "\n",
      "LCS = 0.4\n"
     ]
    }
   ],
   "source": [
    "a, b = data.iloc[1].premis_text, data.iloc[1].hypothesis_text \n",
    "\n",
    "print(\"s1 = \" + a)\n",
    "print(\"s2 = \" + b)\n",
    "\n",
    "print(re.sub(r'[\\.\\?\\'\",]','',a))\n",
    "print(re.sub(r'[\\.\\?\\'\",]','',b))\n",
    "\n",
    "long_seq = lcs(a, b, mode=1, punct=False)\n",
    "print(\"\\nLCS = \" + str(long_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-brain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-velvet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-eight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-dining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-powell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-bleeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-thirty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-polls",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "quality-cassette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_premis</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>cosine_ochiai</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.483046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.474342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.472456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jaccard_sim  intersection_premis  intersection_hypothesis  \\\n",
       "data_split                                                              \n",
       "dev            0.277778             0.312500                     0.75   \n",
       "test           0.272727             0.307692                     0.75   \n",
       "train          0.269231             0.300000                     0.75   \n",
       "\n",
       "            cosine_ochiai  \n",
       "data_split                 \n",
       "dev              0.483046  \n",
       "test             0.474342  \n",
       "train            0.472456  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('data_split')[['jaccard_sim', 'intersection_premis', 'intersection_hypothesis', 'cosine_ochiai']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "natural-moral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_premis</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>cosine_ochiai</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.472456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.536875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.404520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_sim  intersection_premis  intersection_hypothesis  \\\n",
       "label                                                              \n",
       "c         0.277778             0.312500                 0.750000   \n",
       "e         0.320000             0.352941                 0.833333   \n",
       "n         0.222222             0.250000                 0.666667   \n",
       "\n",
       "       cosine_ochiai  \n",
       "label                 \n",
       "c           0.472456  \n",
       "e           0.536875  \n",
       "n           0.404520  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label')[['jaccard_sim', 'intersection_premis', 'intersection_hypothesis', 'cosine_ochiai']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "graduate-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>intersection_premis</th>\n",
       "      <th>intersection_hypothesis</th>\n",
       "      <th>cosine_ochiai</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.442522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.363012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.486664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jaccard_sim  intersection_premis  intersection_hypothesis  \\\n",
       "sentence_size                                                              \n",
       "double            0.238095             0.259259                 0.750000   \n",
       "multiple          0.157895             0.165423                 0.777778   \n",
       "single            0.285714             0.315789                 0.750000   \n",
       "\n",
       "               cosine_ochiai  \n",
       "sentence_size                 \n",
       "double              0.442522  \n",
       "multiple            0.363012  \n",
       "single              0.486664  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('sentence_size')[['jaccard_sim', 'intersection_premis', 'intersection_hypothesis', 'cosine_ochiai']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-implementation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-silver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-greene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-reverse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jewish-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_sim.mean(): 0.3992650096239511\n",
      "cosine_sim.mean(): 0.6121265777697864\n"
     ]
    }
   ],
   "source": [
    "print(f'jaccard_sim.mean(): {data.jaccard_sim.mean()}')\n",
    "print(f'cosine_sim.mean(): {data.cosine_sim.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "possible-windows",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard_sim.std(): 0.16857486902490587\n",
      "cosine_sim.std(): 0.13449692328288737\n"
     ]
    }
   ],
   "source": [
    "print(f'jaccard_sim.std(): {data.jaccard_sim.std()}')\n",
    "print(f'cosine_sim.std(): {data.cosine_sim.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-sodium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-sterling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-trainer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-identity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "devoted-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    5091\n",
       "c    4952\n",
       "n    4685\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single      11988\n",
       "double       2060\n",
       "multiple      680\n",
       "Name: sentence_size, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentence_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "electoral-emphasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    10330\n",
       "test      2201\n",
       "dev       2197\n",
       "Name: data_split, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stretch-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text1: saya makan nasi.\n",
      "Text2: saya makan ikan.\n",
      "cosine.distance: 0.0625\n",
      "cosine.normalized_distance: 0.0625\n",
      "cosine.similarity: 0.9375\n",
      "cosine.normalized_similarity: 0.9375\n",
      "\n",
      "Text1: saya makan nasi.\n",
      "Text2: saya makan ikan.\n",
      "jaccard.distance: 0.11764705882352944\n",
      "jaccard.normalized_distance: 0.11764705882352944\n",
      "jaccard.similarity: 0.8823529411764706\n",
      "jaccard.normalized_similarity: 0.8823529411764706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a, b, c, d = 'test', 'text', 'saya makan nasi.', 'saya makan ikan.'\n",
    "\n",
    "def print_metric(distance, text1, text2):\n",
    "  model = distance_class.get(distance)\n",
    "  \n",
    "  print(f'Text1: {text1}\\nText2: {text2}')\n",
    "  print(f'{distance}.distance: {model.distance(text1, text2)}')\n",
    "  print(f'{distance}.normalized_distance: {model.normalized_distance(text1, text2)}')\n",
    "  print(f'{distance}.similarity: {model.similarity(text1, text2)}')\n",
    "  print(f'{distance}.normalized_similarity: {model.normalized_similarity(text1, text2)}')\n",
    "  print()\n",
    "  \n",
    "print_metric('cosine', c, d)\n",
    "print_metric('jaccard', c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simple-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(path_or_buf='distance.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-scholar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
